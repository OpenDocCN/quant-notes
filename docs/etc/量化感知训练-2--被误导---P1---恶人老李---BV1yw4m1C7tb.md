# 量化感知训练（2）：被误导 - P1 - 恶人老李 - BV1yw4m1C7tb

如何在拍套去中量化，论文。

![](img/a6fb6ff7c7296f6f724810511c557b16_1.png)

这是哪年发的，2017年，那就是2018年，开山之作啊，这是什么意思，整数推理训练用什么电话，什么意思，看不懂，量化推理量化框架，啊有图吗，是什么东西，Clamp，算了看看中文。



![](img/a6fb6ff7c7296f6f724810511c557b16_3.png)

更新在线的，并在这里链接，通过它可以训练在四比特啊。

![](img/a6fb6ff7c7296f6f724810511c557b16_5.png)

这么厉害，这啥广告，我靠IP，没反应。

![](img/a6fb6ff7c7296f6f724810511c557b16_7.png)

唉无限悲伤啊，你好，我想分享巴比特运算，截止目前32位，如果想量化什么什么什么。

![](img/a6fb6ff7c7296f6f724810511c557b16_9.png)

为什么量化，那可以变小啊，此势力在拍照系中从头开始量化，没有外部客户放假，这个好，谁给我发消息，不要发消息，请勿打扰。



![](img/a6fb6ff7c7296f6f724810511c557b16_11.png)

现在我们已经证明了量化的必要性。

![](img/a6fb6ff7c7296f6f724810511c557b16_13.png)

我和你在哪证明呢，几行文字就算证明了，让我们如何量化一个简单的mini的模型。

![](img/a6fb6ff7c7296f6f724810511c557b16_15.png)

使用一个简单的什么什么两个卷积。

![](img/a6fb6ff7c7296f6f724810511c557b16_17.png)

两个全连接啊，class如果是mini的数据集，第一个通道是一，第二通道是三，啊，然后呢，这什么玩意，两卷没有连花呀，这个东西可以删掉，这东西，不是已经缝合在那个什么什么什么里边了。

让我们使用下面简单训练的这个网络啊，这训练函数调成训练状态，这些号放到CPU上，什么，这是什么，训练训练训练，打印LOS主数北京赛六十四四个，EPOLK学习率0。01，什么远古版本，我靠还得关注你。

卧槽，还有一个随机种子，这是什么意思，Loader，Gd，是啥，如果保存模型就保存模型训练。

![](img/a6fb6ff7c7296f6f724810511c557b16_19.png)

没有量化，这是测试，我们得到了99的准确率，现在我们研究一下使用后训练量化，那就是训练后量化，那就是硬量化，要点是将神经网络的激活和权重，转化为八位整数0~255，因此我们在不动点上执行所有算法。

希望精度不会显著下降，为了量化和去量化，一个张亮。

![](img/a6fb6ff7c7296f6f724810511c557b16_21.png)

去量化，去量化是什么意思，我们使用以下公式，float浮点数等于量化减，长椅scale，除以scale加zero point，scale等于这个，映射到了0~25，又，什么呀。

and zerpoint等于什么，下面给出的数量化和量化，如何将负电转化为八倍增量。

![](img/a6fb6ff7c7296f6f724810511c557b16_23.png)

![](img/a6fb6ff7c7296f6f724810511c557b16_24.png)

直接看代码的文字，写的非常的差劲，Name，原主，炼化张亮张亮，Scale zero point。

![](img/a6fb6ff7c7296f6f724810511c557b16_26.png)

这是什么巴比特量化呗。

![](img/a6fb6ff7c7296f6f724810511c557b16_28.png)

难道还能四比特量化，我靠快把它复制下来，或许情西天如来佛祖。

![](img/a6fb6ff7c7296f6f724810511c557b16_30.png)

新建文件叫google qt，K，name trouble是什么意思，为什么会报错，未解析的引用，OK你也没什么用了，最小值是零，最大值是二到，UINT减一最小值，最大值你没有，skill等于rig。

in iso zero point等于这个，我要这个。

![](img/a6fb6ff7c7296f6f724810511c557b16_32.png)

把这个图粘下来。

![](img/a6fb6ff7c7296f6f724810511c557b16_34.png)

如果iniso zero point等于这个，尼鲁，QA等于零零减，X min big skill，那就是，加，Disco，让我想一想，哦这个初始zero point，可以把X面映射到零。

大概是这么个意思，不过这有什么用呢。

![](img/a6fb6ff7c7296f6f724810511c557b16_36.png)

哎我这个任务栏为什么开始散了，这是什么bug，妈的每天都有各种奇怪的问题，哎呀哪那么容易啊，还他妈说两天干完，两周都干不完的，if in the point小于这个就等于q in，啊q tensor。

这是什么东西不错，他是一个标准库。

![](img/a6fb6ff7c7296f6f724810511c557b16_38.png)

导入此名称，任务栏为什么呢，我靠这种什么木马病毒了吗，哎呀这什么问题呀，From collection，Import named the trouble，q tor是一个命名的原主，他是个原主。

但是他有名字，它由三个字段组成，tensor scale和ZERPOINT，这种方式可以方便地将这三个字打包在一起，用于表示量化的张量，在炼化感知训练中，Ps。

量化后的张亮skills方因子是bring0点，这样的方法可以帮助您管理和操作张亮的张亮，Type names，Credentifield names，这东西怎么用啊。



![](img/a6fb6ff7c7296f6f724810511c557b16_40.png)

需要注意的是，刻度是浮点数，而零点是整数，零点，然而现代实现花哨的技巧，近似绕过了什么浮点乘法，这种技巧证明对网络的精度可以忽略不计，胡说八道吗，这四舍五入怎么可能对精度的影响呢。

妈的你一张嘴就是证明证明过程呢，现在我们已经准备好了这些函数，通过修改前向传播来量化激活权重，修改后的前向传播，像这样，我靠这也太复杂了，啊，这哎呀，前向传播，这一点都不简单啊，谁说简单的站出来。



![](img/a6fb6ff7c7296f6f724810511c557b16_42.png)

啊这就完了，在这里我们在输入坑一前对激活进行量化，并使用这个函数量化成函数，这个函数接受，诚信层以及量化激活的激活缩放零点，实行完全量化的承德什么天翻地。



![](img/a6fb6ff7c7296f6f724810511c557b16_44.png)

这不会是硬量化吧，这有个毛用啊。

![](img/a6fb6ff7c7296f6f724810511c557b16_46.png)

还真是硬凉话，我靠看了半天，妈的。

![](img/a6fb6ff7c7296f6f724810511c557b16_48.png)

这不是智障吗，硬量化你也搞这么复杂，这真是浪费我时间，哎呀不应该。

![](img/a6fb6ff7c7296f6f724810511c557b16_50.png)

哎这论文他也不可能是看到标题是什么量化，这是什么东西，这是。

![](img/a6fb6ff7c7296f6f724810511c557b16_52.png)