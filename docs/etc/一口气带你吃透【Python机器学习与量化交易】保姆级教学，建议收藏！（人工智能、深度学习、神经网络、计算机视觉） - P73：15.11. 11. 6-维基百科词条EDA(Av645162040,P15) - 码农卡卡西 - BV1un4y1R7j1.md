# 一口气带你吃透【Python机器学习与量化交易】保姆级教学，建议收藏！（人工智能、深度学习、神经网络、计算机视觉） - P73：15.11. 11. 6-维基百科词条EDA(Av645162040,P15) - 码农卡卡西 - BV1un4y1R7j1

![](img/627674b040a84d319077ce0f2c4f4bc9_0.png)

这节课呀咱们再来看一下，就是当我拿到了一个时间序列的一个，数据之后啊，我首先第一步啊，并不是说要直接进行一个建模，而是说呢要看一下数据内部的一个分布情况，通常呢我们都会做这样一个EDA。

就是用这样一个可视化展示一下，数据内部之间的一些结构，这样呢是便于啊我们之后进行一个建模分析的，嗯首先啊先来说一下这个数据吧。



![](img/627674b040a84d319077ce0f2c4f4bc9_2.png)

这回给大家拿到的数据啊，是关于维基百科上的一个点击量的一个数据，维基百科啊，就是可能咱们国内上的比较少，国外上的都是咱们在国内啊上的，是不是什么百度百科啊，这个百度百科啊。

在国外哈我们就把它叫做一个维基百科，维基百科啊，它里边输入的量是非常大的，而且呢它是一个呃，就是里边不光是有中文那些词条，还有这些法文呐，德文呐或者是英语啊，就是很多种国家语言啊。

都汇集在这个非常大的维基百科当中了。

![](img/627674b040a84d319077ce0f2c4f4bc9_4.png)

然后我们拿到的一个数据啊，就是对于现在我们来看左边是一些词条啊，比如说现在关于某一个明星，或者说包于某一个事件，或者是关于某一个知识点啊等等，反正就是你能想到的东西啊，在维基百科上基本上都是可以搜到的。

关于这样的一个词条。

![](img/627674b040a84d319077ce0f2c4f4bc9_6.png)

然后呢后右边是它的一个点击率，这个点击率啊就是随着时间的一个变化。

![](img/627674b040a84d319077ce0f2c4f4bc9_8.png)

我们来看它是从这个15年的一个7月1号啊，一直到这个16年的一个12月31号。

![](img/627674b040a84d319077ce0f2c4f4bc9_10.png)

一共啊大概是有这么一年多的一个数据，然后我们其实啊，就是比如说我们现在接到一个任务，然后对于每一个词条啊，我们想预测一下它未来的一个点击率，可能会是多少，但是呢咱们就是得想这么个事啊，在咱们建模之前啊。

我们得考虑一下，就是这批数据来了之后，我们直接建模就可以吗，比如说这批数据来了之后，我直接啊就把这个数据，然后划分成这样一个时间序列啊，一个个都是时间序列，然后我直接就是建立回归模型，得出这样一个结果。

这样可取吗，或者说这种方法做的合适吗。

![](img/627674b040a84d319077ce0f2c4f4bc9_12.png)

咱们现在就要围绕着这个问题来讨论一下，首先呢我们就得想一想。

![](img/627674b040a84d319077ce0f2c4f4bc9_14.png)

对于我们最终啊进行一个建模，影响因素在哪里啊，可能来说现在光从这个数据层面上。

![](img/627674b040a84d319077ce0f2c4f4bc9_16.png)

我们看不出来太多东西，所以说呢我们需要做这样一些可视化展示。

![](img/627674b040a84d319077ce0f2c4f4bc9_18.png)

通过一些可视化展示啊，我们就来看一下数据内部啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_20.png)

它存在着什么样的规则呢，第一步我先看了一下，就是打印了一下。

![](img/627674b040a84d319077ce0f2c4f4bc9_22.png)

用pandas as打印了一下我的一个TRA的info，train info里边呢他会告诉我啊，当前的一个词条的一个当前数据的一个大小，以及呢就是它有多少个列。

还有啊就是它的一个呃memory的一个大小是多大，我们来看现在的一个memory啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_24.png)

基本上是占了我的600多兆，咱们这个数据量是非常大的，它有个十百千万10万。

![](img/627674b040a84d319077ce0f2c4f4bc9_26.png)

它有14万个词条，这个只是取了维基百科数据当中啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_28.png)

很少的一部分，一共是有14万个词条，然后每个词条啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_30.png)

随着每个时间的一个点击量是等于多少的，那咱们来看啊，就是说现在的我的一个数据啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_32.png)

它里边都是flow类型吧，都是一个浮点数，18。零十一。05。零十三。0。

![](img/627674b040a84d319077ce0f2c4f4bc9_34.png)

哎我们来说这里边好像是没有一个小数吧，比如说15。1啊，这26。2它最终啊都是一个点零，但是呢它就跟一个整数啊是类一样的吧，它没有出现个点3。5。6吧，所以说第一步啊。



![](img/627674b040a84d319077ce0f2c4f4bc9_36.png)

我可以把这样一个flow类型，转换成一个int类型吧，这样做有什么好处啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_38.png)

flow类型是非常占内存的，但是呢int类型我们占内存就比较少了。

![](img/627674b040a84d319077ce0f2c4f4bc9_40.png)

我们可以来尝试做一下这样一个事情，然后呢在这里啊我用了pandas as的一个函数，就是把我的一个数值啊进行转换，然后呢我把当前的一个flow类型给它指定成，转换成我的一个integer类型。

在这里啊写了一个循环，就是说对于啊我所有的列当中啊，每一个列啊都要去做这样一个转换，转换完之后呢。

![](img/627674b040a84d319077ce0f2c4f4bc9_42.png)

我再打印一下我当前的这个data frame啊，点HIIT一下，HIIT完之后啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_44.png)

这就是结果十八十一五十三十四，这都是我的结果吧，现在呢原来是一个点零。

![](img/627674b040a84d319077ce0f2c4f4bc9_46.png)

现在点零去掉了吧，咱们来看一下，就是当我去掉了一个。

![](img/627674b040a84d319077ce0f2c4f4bc9_48.png)

就是当我把flow类型转换成int类型之后啊，它的一个变化是什么样，现在我们来看现原来是600多兆吧，现在呢变成了一个int类型。



![](img/627674b040a84d319077ce0f2c4f4bc9_50.png)

它只有300多兆了吧，也就是说啊，如果说你的数据量比较大的情况下啊，你就是可能你的内存是不够了，或者说运行速度比较慢，咱们也可以啊，把这样一个服务类型转换成int类型。

这样类型啊相对来说是非常省空间的啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_52.png)

我们就可以先做这样一个转换，然后啊我就要想一个事了。

![](img/627674b040a84d319077ce0f2c4f4bc9_54.png)

在我的一个维基百科这个数据当中啊，是不是说他哪个国家语言都有啊，那我就是对于不同的语言，我建立同样一个模型去预测。



![](img/627674b040a84d319077ce0f2c4f4bc9_56.png)

这样科学吗，好像来说不太清楚是吧，所以说我们先要来看一下，在我的一个维基百科当中啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_58.png)

我这个不同的国家啊出现的一个瓷瓶，或者说不同的一个国家出现的一个个数。

![](img/627674b040a84d319077ce0f2c4f4bc9_60.png)

分别有多少啊，我想分国家的来看一下。

![](img/627674b040a84d319077ce0f2c4f4bc9_62.png)

在这里呢我就用到了这个re e啊，就是我去做这样一个匹配。

![](img/627674b040a84d319077ce0f2c4f4bc9_64.png)

在这里呢我search一下设置什么，设置一下我们的数据当中啊，我们来看数据当中啊，它有一个位置，就是说有些位置啊它有ZHZH表示中国吧，还有一些呃英国啊。



![](img/627674b040a84d319077ce0f2c4f4bc9_66.png)

德国啊，法国啊等等啊，它每个都有这样一个分别的一个标志符的。

![](img/627674b040a84d319077ce0f2c4f4bc9_68.png)

在这里呢我们就来看一下，我对于不同的标识符啊做这样一个映射，然后可以看一下我不同的标识符啊，它的一个国家的一个数量分别是多少，就相当于是把我的一个词条啊，就是做了一个分类，现在咱们拿到的就是所有词条。

在上一层，我们又做了一个分类，分成了中国，英国，美国。

![](img/627674b040a84d319077ce0f2c4f4bc9_70.png)

法国，德国啊，分成几个国家，咱们来看现在呢我最终啊用这样一个counter，用这样counter又统计了一下他的个数啊，就是我们的一个说不同语的国家，比如说英国就是大概有2万多个，然后日本2万多个。

然后中国中国有1万多个，还有一些其他的国家，其他国家还有俄罗斯啊什么的啊，反正就是对于不同国家，我又进行了一个统计，统计完结果现在拿出来了。



![](img/627674b040a84d319077ce0f2c4f4bc9_72.png)

还有一个NAN那NN的意思啊，就是说啊，当前这个国家，它是可能是出现一些错误的情况下。

![](img/627674b040a84d319077ce0f2c4f4bc9_74.png)

我们给他指定成了一个NA的一个值。

![](img/627674b040a84d319077ce0f2c4f4bc9_76.png)

然后呢对于当前的一个数据啊，我们就要来进行一个划分了，在这里呢要对我的data frame进行一个所属的划分，data frame当中啊，我就判断一下，如果说等于EN的，然后我也单独拿出来啊。

他就是单独拿出来一个列，叫做一个EN。

![](img/627674b040a84d319077ce0f2c4f4bc9_78.png)

然后呢z hr咱们对中国在南图拿出来啊，叫做一个ZH，这回呢，我就是说相当于是先把我的一个所有词条啊，基于国家又做了一个划分，想看一下，就是不同国家啊，它的一个变化的情况是长什么样的。



![](img/627674b040a84d319077ce0f2c4f4bc9_80.png)

那现在啊就是我想画的是一个总数，就是说咱们现在不是有每一些国家的。

![](img/627674b040a84d319077ce0f2c4f4bc9_82.png)

一个词条吗，那我想看一下，就是说这些词条啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_84.png)

他的一个总数变化的情况先啊，就是不挨个资料去看。

![](img/627674b040a84d319077ce0f2c4f4bc9_86.png)

而是说先去观察一下它的一个总数，在这里啊，我就得到了啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_88.png)

对于不同国家，它的一个点击量的一个情况是长什么样子的，嗯可以明显看出来。

![](img/627674b040a84d319077ce0f2c4f4bc9_90.png)

就是说这个英文啊，要比其他的语言都要高一些吧。

![](img/627674b040a84d319077ce0f2c4f4bc9_92.png)

然后其他语言可能有一些奇怪，就是随着时间变化，我们来看这个红色的怎么这么奇怪。

![](img/627674b040a84d319077ce0f2c4f4bc9_94.png)

他是哪个国家的，红色的是俄罗斯的RUSSI的，对俄罗斯啊可能来说在第400天，然后是从15年开始，第400天，他这个阅读量开始猛增，那它可能在那个时间点发生了一些额外情况吧，或者说有一些重大的事件。

导致很多俄罗斯人啊都去看啊，这个东西，然后可能有一些可能，有一些就是国家性比较重视的东西，所以说它才能出现一个这么奇怪，来看这个值啊，基本上是正常值的一个三倍了，哎这块可能会出现一些问题吧。



![](img/627674b040a84d319077ce0f2c4f4bc9_96.png)

或者说出现了一些影响，那么从一个平均趋势来看。

![](img/627674b040a84d319077ce0f2c4f4bc9_98.png)

英国是占了第一，咱们中国呢，中国咱们大家可能用维基百科比较少，我们来看一个蓝色的，蓝色的约等于很低的一个点了，因为咱们现在啊谷歌是被屏蔽了，只能上百度，百度百科已经是取已经是怎么说呢，一个垄断地位吧。



![](img/627674b040a84d319077ce0f2c4f4bc9_100.png)

咱没办法上谷歌啊，这个对这个影响我觉得还是蛮大的，然后啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_102.png)

这是说我们现在对维基百科的一个点击量，我们可以做这样一个嗯，跟时间相关的一个序列出来。

![](img/627674b040a84d319077ce0f2c4f4bc9_104.png)

那从这个序列当中啊，我们也看出来，当我们想建模的时候啊，不同的国家它的一个情况是有很大差异的吧，那我们就是能把这个东西进行一个整体建模吗，咱们是不是可以把它进行一个分国家建模啊。

比如说英文的我建立一个英文预测模型，中文的建立一个中文预测模型，我们可以啊，就是对不同的国家分别建立不同的模型吧，因为呢就是不同的国家，它的一个视频的一个点击情况差异很大吧，这个差异很大。

我们就不能整体去对待了，我们需要分别去做这样一个事情的。

![](img/627674b040a84d319077ce0f2c4f4bc9_106.png)

然后呢这个时间序列我们还可以分析什么，分国家进行分析啊，我们也可以看这样一个各自的异常点。

![](img/627674b040a84d319077ce0f2c4f4bc9_108.png)

因为呢就是整体上情况下来看，很难去观察，就是它这个再有一些其他影响因素，比如说嗯这个语种营养因素，或者是其他营养因素，之前我还做过一个HTTP的一个异常流量检测，在做检测的时候啊，你也不能整体的去看。

整体的去看啊，这个大趋势很难看出什么东西，我们需要比如说你分网段的去看嗯，在某一个网段下，可能这个网段下它都是一个公司，或者说啊它是一种就是要么是一个公司啊，要么是一个区域。

我们分网段可以很明显的看出来，不同网段它的一个活动的一个情况，是长什么样子的，那这里呢就是我们第一步啊，我们是分国家先进行了一个统计。



![](img/627674b040a84d319077ce0f2c4f4bc9_110.png)

然后进行了一个观察，那下面呢就是说嗯，我们不光啊能分郭嘉进行观察吧。

![](img/627674b040a84d319077ce0f2c4f4bc9_112.png)

我们也可以啊分词条进行观察，对于不同的词条呢，我们也可以打印出来这样一个结果。

![](img/627674b040a84d319077ce0f2c4f4bc9_114.png)

就是看一下，在这里我随机选择了几个值，比如说额选了个id号啊，从1~5000，然后随便选了几个，在这里呢我就看一下。



![](img/627674b040a84d319077ce0f2c4f4bc9_116.png)

比如说ENGLISH的里边啊，他的一些不同的词条，它的一个阅读量的一个情况。

![](img/627674b040a84d319077ce0f2c4f4bc9_118.png)

那从这里啊就是可以明显看出来一个趋势，对于不同词条啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_120.png)

它都是有这样一个热度的，在这里呢我们来看，比如说一个词条，他在前500天啊都是默默无闻吧。

![](img/627674b040a84d319077ce0f2c4f4bc9_122.png)

然后突然在第500天爆发了，然后爆发的量是非常非常大的，这个也就是说啊针对于一些个别词条来说呀。

![](img/627674b040a84d319077ce0f2c4f4bc9_124.png)

啊它都会呈现出来这样一种趋势，嗯对于就比如说这个是一个词条预测吧，那其实可能一些其他任务啊跟我们的还不一样，词条来说啊，可能他说今天哎呀这东西就突然火了，那它可能出现这样一个趋势。



![](img/627674b040a84d319077ce0f2c4f4bc9_126.png)

我们也可以通过这个词条啊来判断一下，当时啊他的一个非常爆火的一个词是等于什么。

![](img/627674b040a84d319077ce0f2c4f4bc9_128.png)

我们就可以做这样一个筛选嘛，就是看他这样一个浮动嘛。

![](img/627674b040a84d319077ce0f2c4f4bc9_130.png)

如果说它的浮动这个差异性特别大，那这个词是不是说它产生了一个，当时的网红效应啊，我们也可以分析一下啊，在当时网红都有哪些东西。



![](img/627674b040a84d319077ce0f2c4f4bc9_132.png)

就可以通过所有的词频啊去，就是可以通过所有的一个词条的一个。

![](img/627674b040a84d319077ce0f2c4f4bc9_134.png)

变化情况啊，来找出来这些网红的词，然后进行一个统计分析。

![](img/627674b040a84d319077ce0f2c4f4bc9_136.png)

我们来看这个每个词啊，都会有都会呈现出来这样一种趋势吧，有很多词哎。

![](img/627674b040a84d319077ce0f2c4f4bc9_138.png)

在这个词条当中都呈现出来这样一种，就是突然爆发性的一个趋势，那这个就是对于单个词来说啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_140.png)

我们可以预测一下它的一个结果，那我们不光可以对单个词去看一下。

![](img/627674b040a84d319077ce0f2c4f4bc9_142.png)

它当前的一个结果，也可以啊，对我的一个整体去看一下，比如说啊现在我想看了一下，对于中文来说，我现在想看一下不同国家的人呐，他关注的点都在哪，他关注点越高的，肯定是搜索也越高的吧，我可以看一下。

在当下这个时间段，比如说中国啊他关注的一些热点在什么地方。

![](img/627674b040a84d319077ce0f2c4f4bc9_144.png)

然后这个呃法国关注的热点。

![](img/627674b040a84d319077ce0f2c4f4bc9_146.png)

德国关注的热点，我们可以啊把他的搜索的一些排行都拿出来。

![](img/627674b040a84d319077ce0f2c4f4bc9_148.png)

看一下它的一个热点都是在什么地方，这就是把它的一个结果都拿出来。

![](img/627674b040a84d319077ce0f2c4f4bc9_150.png)

那最后啊我还可以统计一下，就是关于这些热点啊，它随时间变化的一个情况是长什么样子的。

![](img/627674b040a84d319077ce0f2c4f4bc9_152.png)

这个也是我们可以统计出来的啊，就是说在这里啊给大家又看了一下。

![](img/627674b040a84d319077ce0f2c4f4bc9_154.png)

对于一份时间序列的一个数据来之后啊，嗯我们通常情况下。

![](img/627674b040a84d319077ce0f2c4f4bc9_156.png)

比如说你现在任务是要进行预测，那我在预测之前啊，我也需要先把我的数据啊进行一个了解，通常呢我们管这个东西啊，叫做一个EDA，就是一个探索性的数据分析，在我的一个探索性数据分析当中啊。

我就要尽可能多的进行一个可视化展示，展示一下数据内部中的一个结构，以及呢我们可能根据我的一个任务啊，感兴趣的这些点，把这些点都展示出来，我看一下这些点有什么样的变化规则，它能够给我们提供什么信息。

这些信息啊都是我们在之后啊，在建模的时候可能会用到的，在这里啊，就是啊前面这些东西啊，我都没太看懂它具体表示什么含义，然后呢这块有一个琅琊榜啊，这个我看出来了，就是说在诶大概是哪年15年的时候吧。

还是16年时候出的这个拉琊榜，我记不太清了，这个可也是当时中国的一个热点吧。

![](img/627674b040a84d319077ce0f2c4f4bc9_158.png)

这个当时我记着点击率是非常高啊，只破了一个卫视的一个舒适日记录了吧。

![](img/627674b040a84d319077ce0f2c4f4bc9_160.png)

那这个就是当前啊给大家看了一下呃，我们对一个维基百科数据拿过来之后啊，可以先给它分模块的进行一个展示，展示完之后呢，咱们就想一想我要不要分国家进行建模啊，这个只是说我做了第一层分类是分国家。

第二层分类呢，第二层分类我还可以分一些文章的种类吧，你是科技类啊，教育类啊，还是什么类啊，对于不同类都可以分别进行这样一个展示的，111旦啊，就是说你把这个类目啊分的更细，分的越细啊。

你的模型建立的应该就是会更精确一些的，但是呢你的一个任务量也会更大，嗯这块还有一点就是有个fail aa0，费用AA0的意思啊，就是说嗯拿到这些数据的时候啊。



![](img/627674b040a84d319077ce0f2c4f4bc9_162.png)

大概观察了一下，它里边是有一些缺失值的，比如说这块可能有一些缺失值。

![](img/627674b040a84d319077ce0f2c4f4bc9_164.png)

缺失值啊，它这个嗯这个就是啊这个公开的一个数据集啊，他是这样说的，缺失的一个数据啊，他也不知道到底是零还是缺失的，反正呢就是这点啊，咱们就暂且当成是一个零就好了，相当于是今天啊没有点击量啊。

因为当时的数据就是一个空白，他也是跟我们说了一下啊，就是最好用零进行一个填充的。

![](img/627674b040a84d319077ce0f2c4f4bc9_166.png)

那这个就是我们的一个啊，关于维基百科这样一个EDA的一个展示嗯。

![](img/627674b040a84d319077ce0f2c4f4bc9_168.png)

大家如果说有时间的话，也可以把这个嗯维基百科这个数据啊。

![](img/627674b040a84d319077ce0f2c4f4bc9_170.png)

自己进行一个预测。