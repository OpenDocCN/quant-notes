# 金融中的人工智能和机器学习 - 第16讲 - 最大保证金分类器 - P1 - 量化Quantgirl - BV1Zx421D7eV

![](img/0e79afa625457cb76a29c9396072622a_0.png)

大家好，欢迎回到我们的金融人工智能和机器学习课程，在这段视频中，我们想看看支持向量机作为另一种分类方法，正如你所记得的，我们看到的最后一个视频，我们稍后会更详细地看到这一点，在金融中常用的分类应用中。

至少，例如，在信用风险管理中，我们要对好的和坏的贷款进行分类，保险经济学中的违约客户与非违约客户，保险管理可以是，我们想识别和分类那些最容易，终止他们的合同，转到另一家保险公司。

支持向量机是另一种分类方法，因此，它与k个最近邻非常相似，但更复杂的是，如果我们谈到支持向量机，通常，这是三种不同方法的总结术语，我们从所谓的，然后会跳到支持向量分类器，如果我们扩展支持向量分类器。

我们得到支持向量机，我们会说到这一点的，大概下期视频，我们必须从所谓超平面的基本定义开始，什么是超平面，p维空间中的p维超平面是平面主题，而这样，尺寸为p-1，例如，在二维中，如果我们有。

超平面是一条线，例如，这是一个超平面，这是一个超平面，甚至这是一个超平面，所以这是一条线，二维空间中的一条直线，三维空间中的平面。



![](img/0e79afa625457cb76a29c9396072622a_2.png)

是一架飞机，所以你可以看到这是怎么回事，如果这是一个三维空间。

![](img/0e79afa625457cb76a29c9396072622a_4.png)

例如，嗯，我现在可能需要画这个素描，可能，例如，不管是什么。

![](img/0e79afa625457cb76a29c9396072622a_6.png)

超平面，所以它在z轴上被切割，所以这可以是让我为你画一个草图，让我们用，例如，这将是三维空间中的一个平面，让我们说p，不是P，但那等于，就三个吧，所以如果x，Y和三个坐标，这是超平面。

这个蓝色平面在z等于3的地方穿过三维空间，所以大家可以看到，超平面将p维空间分成两半，它是由这个方程定义的，你有坐标0+1的线性组合，以此类推直到+beta p乘以xp，这需要等于零。



![](img/0e79afa625457cb76a29c9396072622a_8.png)

这样你就得到了一个超平面，那是一个很简单的超平面，你现在可以看到为什么我们在这里使用超平面了，在最开始的时候，因为在平面的二维情况下，这样的线穿过平面，把它切成两半。



![](img/0e79afa625457cb76a29c9396072622a_10.png)

例如，如果我们在这里有一些观察。

![](img/0e79afa625457cb76a29c9396072622a_12.png)

这里和这里，也许在这里，我们有与这些点相关的某些特征。

![](img/0e79afa625457cb76a29c9396072622a_14.png)

![](img/0e79afa625457cb76a29c9396072622a_15.png)

然后比如说，这可能是一个决策边界，这条红线意味着在上面的蓝色空间里，嗯，这里所有的观测结果都被归类为蓝点，那些低于这条线的被归类为红色类，所以超平面被用来分类。



![](img/0e79afa625457cb76a29c9396072622a_17.png)

作为输入数据，我们应该如何做好这一点，我们有n倍p的观测，我们得到了p维空间中n个观测值的数据矩阵，每个观察都属于一类，那就是我们有响应，定性响应变量y1到ym，我们有-1或-1作为响应变量，可能的值。

减一代表一个类，一个代表另一个类，所以我们只有两节课，现在我们可以将所有这些模型扩展到我们有更多类的情况下，就像，例如，嗯默认，三A双A评级，等等，它与收视率很好，但是我们一开始只有两节课。

负一节课就是一节课，一个是另一个，嗯，我们有一个带有观测特征p向量的测试观测，这是X星，x一星直到xp星，作为输出，我们用分离超平面得到x星的分类，所以我们用一个超平面把p维空间切成两半。

然后我们就可以很简单地决定这些观察属于哪一类。

![](img/0e79afa625457cb76a29c9396072622a_19.png)

基于分离超平面的分类器，例如，如果我们有这些蓝色和红色的观察，嗯，你可以看到所有这些线条，他们把蓝点和红点分开，然后我们就可以说好了，例如，如果我们用这条线和这个分离超平面，然后上面的一切，蓝色类。

下面的都是红色类，我们可以用超平面进行分类，所以它非常，很简单的现在问题。

![](img/0e79afa625457cb76a29c9396072622a_21.png)

如果一个分离超平面存在，并且它不一定存在，可能是没有分离的超平面。

![](img/0e79afa625457cb76a29c9396072622a_23.png)

很简单的场景，例如，如果我们把所有这些点混合在一起，那些蓝点和红点，如果这些是例如，这些是红点，如果我加一些红点，如果我加一些没有对不起，如果我在这里加一些蓝点，你很容易在没有证据的情况下看到。

很难找到一个分离的超平面。

![](img/0e79afa625457cb76a29c9396072622a_25.png)

也就是说，它必须是线性的，这就是超平面的定义，所以大家可以看到，试着嗯，插入分离超平面。

![](img/0e79afa625457cb76a29c9396072622a_27.png)

它不会起作用的，所以在这种情况下没有，如果存在一个分离的超平面。

![](img/0e79afa625457cb76a29c9396072622a_29.png)

然后我们有无限多这样的超平面。

![](img/0e79afa625457cb76a29c9396072622a_31.png)

你可以看到我可以在这里添加无数的超平面，只要每个超平面仍然分隔所有这些点。

![](img/0e79afa625457cb76a29c9396072622a_33.png)

所以我们有一个无限的数字，问题是我们应该用哪一个。

![](img/0e79afa625457cb76a29c9396072622a_35.png)

这就是我们得到最大边距分类器的地方，现在呢，自然选择是匹配最大边距超平面，哪一个是离训练观测最远的分离超平面，我们要做的是，我们首先计算每个训练观测的垂直距离。



![](img/0e79afa625457cb76a29c9396072622a_37.png)

到给定的分离超平面。

![](img/0e79afa625457cb76a29c9396072622a_39.png)

我们实际上可以做到这一点，如果我删除一些我的。

![](img/0e79afa625457cb76a29c9396072622a_41.png)

这里的图纸，例如，如果我们使用这一个，例如，我们计算出，让我看看这几乎垂直于超平面，从每一边你都可以看到这个，然后我们试着找到分离超平面，这样最大值，这就是所谓的边距，最大距离很好，它是最大的。

这可能不是最大边距分类器，因为你可以看到现在我已经转移了线，左边的超平面。

![](img/0e79afa625457cb76a29c9396072622a_43.png)

即使这些距离。

![](img/0e79afa625457cb76a29c9396072622a_45.png)

例如，这个现在变大了，这个变小了，所以实际上我们试图在一年和一年之间的某个地方安装超平面，到蓝点的距离，与红点的距离是等距的。



![](img/0e79afa625457cb76a29c9396072622a_47.png)

这就是如何构造最大边距分类器的方法，所以我们计算这些距离，这样的最小距离称为边距，然后我们最大化利润，它是边界最大的分离超平面。



![](img/0e79afa625457cb76a29c9396072622a_49.png)

所以这就是我们得到的，你可以在这里看到，距离，保证金现在是最大的，实际上，现在考虑蓝点和红点是一样的，有趣的是实际上，你可以在这里看到，在这里加一个红点或者在左边加一个蓝点。

实际上不会改变最大边距超平面和分类器，为什么呢？因为最大边距分类器只依赖于此，而这三点上的这一点，这就是为什么它们被称为支持向量，它们支撑着超平面，而这些是唯一的点，在p维空间中这些是向量。

这些是决定分离超平面的唯一点或向量，改变这些支持向量，我们得到了一个不同的分类器，我们会得到一个不同的分离超平面，但实际上如果你在左边或右边加上任何点，分类器不会改变。

这就是为什么这些实际上被称为支持向量，现在你可以看到为什么以后，它被称为支持向量分类器和支持向量机，但是，这仍然是最大边距超平面和最大边距分类器。



![](img/0e79afa625457cb76a29c9396072622a_51.png)

我们如何构建这个，嗯，更详细的好，最大裕度超平面是特定优化问题的解，嗯，我们需要最大限度地扩大利润，这是M，所以我们在寻找这些参数，贝塔零，以此类推，使得m最大化，根据我们的总结。

我们对系数的平方-j求和，他们需要加起来一个，为什么我乘以嗯，实际上，超平面需要大于或等于m，意思是什么会真正记住为什么i是负一或一，这个约束二六，确保每个观察都在超平面的正确一侧，我们有一些缓冲。

一些保证金，M，那很清楚，所以实际上我们在这个区域之间也有一些点。

![](img/0e79afa625457cb76a29c9396072622a_53.png)

例如，这里，在这里，我们可能有。

![](img/0e79afa625457cb76a29c9396072622a_55.png)

如果换了，但这是边际和约束，2-5确保每次观测与超平面至少有m的距离，所以需要这样，然后我们最大化并选择决定超平面的系数，使得m为最大值。



![](img/0e79afa625457cb76a29c9396072622a_57.png)

这是一个非常简单的分类器，如果存在分离超平面，我们应该使用最大裕度分类器，但问题是总是这样吗，这是不可分离的情况，我以前试过画这个。



![](img/0e79afa625457cb76a29c9396072622a_59.png)

但你可以从这里的任何地方开始，试着找到一个超平面把这些点很好地分开，否，这里还有红点，你可以上去，这也没关系，但是我们这里有一个红点，你可以看到，我不能把一条线穿过这个平面，如果左边没有红点。

在这个超平面的右边有一些蓝点，所以这是个问题，好啦，所以这不是单独的案子，在这种情况下，我们没有分离超平面。



![](img/0e79afa625457cb76a29c9396072622a_61.png)

我们现在不能使用最大边距分类器，如果存在分离超平面，我们应该一直使用基于它的分类器吗，不幸的是，答案是否定的，因为它对新的观测非常敏感，正如你在这里看到的，例如，如果这是最大边距分类器，如果我加一个点。

让我们在这里说，这改变不了什么，但在这种情况下，我们在这里加了一点，如你所见，与其搬家，嗯，分离的超平面。



![](img/0e79afa625457cb76a29c9396072622a_63.png)

假设这是旧的，我们说好吧，这个也可以，这是我们犯的一个错误，但这还是可以的，因为最大边距分类器将所有蓝色点和所有红色点分开，你可以看到它非常敏感，它突然给了我们这个决定界限，所以即使分离超平面存在。

可能是我们不想要这种程度的完美，因为这样倾斜度就会很低，方差会很大，所以这就是为什么在下一步，在下一个视频中将扩展最大边距分类器，允许一定程度的误差。



![](img/0e79afa625457cb76a29c9396072622a_65.png)

![](img/0e79afa625457cb76a29c9396072622a_66.png)