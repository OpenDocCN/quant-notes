# 从零开始做量化｜5 利用深度学习进行训练 - P1 - 小蓝帽go - BV1gymhYcE7j

OK我们这一节也是比较重要的一节啊，就是这个模型训练的部分好。

![](img/d5e0409fe29bb60709a69ec7761a2af2_1.png)

我们打开这个train嗯。

![](img/d5e0409fe29bb60709a69ec7761a2af2_3.png)

可以看到这个propose preprocess，DATASET和这个啊device data loader。



![](img/d5e0409fe29bb60709a69ec7761a2af2_5.png)

这两个我就先不细说了哦。

![](img/d5e0409fe29bb60709a69ec7761a2af2_7.png)

这个这两个是透视里面对数据集加载的机制嗯。

![](img/d5e0409fe29bb60709a69ec7761a2af2_9.png)

唯一要说的是，因为我是用的是Mac，然后训练数据很大，我不得不进行一下处理，就是把大的训练集进行切分啊，可以看到我这边有一个separate f，这个就是把那个大数据进行切分的。

然后我会先shuffle整个数据集。

![](img/d5e0409fe29bb60709a69ec7761a2af2_11.png)

然后分段加载到这个内存里面，你可以根据你自己的环境写这个data loader和DATASET。

![](img/d5e0409fe29bb60709a69ec7761a2af2_13.png)

也可以直接用我的嗯。

![](img/d5e0409fe29bb60709a69ec7761a2af2_15.png)

这里就不先展开了，然后可以看到这个就是模型的最终的哦。

![](img/d5e0409fe29bb60709a69ec7761a2af2_17.png)

模型结构的部分了。

![](img/d5e0409fe29bb60709a69ec7761a2af2_19.png)

attention先不说，我们先来看一下这个sequence model。

![](img/d5e0409fe29bb60709a69ec7761a2af2_21.png)

也就是整个量化模型的主要的框架，我们可以看到这一个部分哦。

![](img/d5e0409fe29bb60709a69ec7761a2af2_23.png)

我在这边呢先是定义了个定义了一个LSTM，L s t m，它是对股票时间序列，也就是我们之前讲的那些用那些阿尔法，用定长的时间窗口取出来，进行拼接来的这个序列特征进行特征提取。

然后像这些innocence，还有industry，还有our的呃，特征呢就是通过NOP的方法，把上市公司的介绍。



![](img/d5e0409fe29bb60709a69ec7761a2af2_25.png)

股票指数交易时间，这些内容通过高维嵌入的方式加入到模型中去，然后最后呢就是一个MLP哦。

![](img/d5e0409fe29bb60709a69ec7761a2af2_27.png)

也就是多层感知机把所有的特征进行拼接，然后进行非线性的计算。

![](img/d5e0409fe29bb60709a69ec7761a2af2_29.png)

然后最终输出的多分类的结果。

![](img/d5e0409fe29bb60709a69ec7761a2af2_31.png)

可以看到这个forward的，就是模型的一个计算的一个流程噢，我会先取这些embedding，就是那些嗯NO，通过NOP拿来的这些embedding。



![](img/d5e0409fe29bb60709a69ec7761a2af2_33.png)

然后对序列特征，就是这个序列特征进行LSTM的特征提取。

![](img/d5e0409fe29bb60709a69ec7761a2af2_35.png)

然后我在这边呢是增加了一个attention，可以看到这个attention就是其实就是这个模型。

![](img/d5e0409fe29bb60709a69ec7761a2af2_37.png)

我在这边加一个attention，就是一个自注意力的机制，自注意力机制加在这边呢，是因为OSTM虽然是，但是长短期记的。



![](img/d5e0409fe29bb60709a69ec7761a2af2_39.png)

但是长的上下文关联能力可能还不是很强，然后第二点的话也是attention，可以增加一个动态权重的特征，提取就是不同的特征在相同位置上的weight。



![](img/d5e0409fe29bb60709a69ec7761a2af2_41.png)

它是不一样的。

![](img/d5e0409fe29bb60709a69ec7761a2af2_43.png)

然后我们在这边的话，是把所有的这些特征额进行。

![](img/d5e0409fe29bb60709a69ec7761a2af2_45.png)

包括embedding，再包括这个LSTM的一个结果，再包括attention的结果，慷慨的在一起，这个序列结果，attention LSTM和attention结果一起结合呢。

也是一个残差的一个一个思维在这边。

![](img/d5e0409fe29bb60709a69ec7761a2af2_47.png)

然后我们最终通过MOP把这个模型呢，把整个数据啊通过非线性的一个方式进行计算。

![](img/d5e0409fe29bb60709a69ec7761a2af2_49.png)

并输出多分类的一个结果。

![](img/d5e0409fe29bb60709a69ec7761a2af2_51.png)

我们接下来可以看一下这个loss的一个设计，整个模型的loss我这里设计的比较复杂，它是由两个部分，就是可以看到这个对，这里边一个是focal loss和一个distance loss，Foc。

罗斯在这边的话，是处理数据不平衡的分类问题的，我这里还额外增加了一个batch alpha的一个概念，可以看到这边嗯。



![](img/d5e0409fe29bb60709a69ec7761a2af2_53.png)

贝斯L法增加，在这边的话，是就还是想再进一步增加数据比较少的，然后就是股票涨得好的。

![](img/d5e0409fe29bb60709a69ec7761a2af2_55.png)

那部分的数据的学习能力，然后这个distance loss在这里的话，是我自己脑补的。

![](img/d5e0409fe29bb60709a69ec7761a2af2_57.png)

不一定对，因为我我觉得股票的1234呃，应该是0123的标签的预测，不是简单的分类问题，而是一个有序的问题。



![](img/d5e0409fe29bb60709a69ec7761a2af2_59.png)

比如说模型给三这个标签，也就是说长得最好的那部分的呃，那一部分的标签的概率预测得很高，然后你同时呢又给他这个零这个标签，也就是说他觉得跌的这个概率很高，那肯定是不对的。

就会就意思就是说模型又会觉得他长得好，又会觉得他跌的多，那我会在这里给他一个惩罚，如果是相近的，比如说二和三的概率是同时比较高，或者说零和一的呃。



![](img/d5e0409fe29bb60709a69ec7761a2af2_61.png)

零和一的这个概率比较高呢，那我觉得还是OK的。

![](img/d5e0409fe29bb60709a69ec7761a2af2_63.png)

因为毕竟上一节里面，我的label阶段是比较绝对的，然后我觉得在这里多分类还是会损失很多信息，就想设计这么一个机制哦，不一定对，我后面可能也会考虑把它重新更改或者优化嗯。



![](img/d5e0409fe29bb60709a69ec7761a2af2_65.png)

虽然我这里这个label的设置也是参考了一些paper，但但我感觉还是有些离谱，所以额外增加了一个啊这个lost的设计。



![](img/d5e0409fe29bb60709a69ec7761a2af2_67.png)

然后OK我们这一节就结束了，下一节的话，我会利用GBT来对我整个量化模型进行优化。

![](img/d5e0409fe29bb60709a69ec7761a2af2_69.png)